<!DOCTYPE html>
<html>

<head>
  <!-- Google tag (gtag.js) -->
  <script async src=""></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

  </script>
    <style>
      .image-row {
          display: flex;
          justify-content: space-between; /* Ensures images are spaced evenly */
          align-items: center;
          margin-top: 20px;
      }
      .image-row img {
          flex-grow: auto; /* Allows each image to grow */
          max-width: 35%; /* Limits the width of each image to one-third of the container */
          height: auto; /* Maintains aspect ratio */
      }
  </style>

  <meta charset="utf-8">
  <meta name="description" content="CinePile: A Long Video Question Answering Dataset and Benchmark">
  <meta name="keywords"
    content="GPT-4, GPT-4o, Gemini, Foundation Model, Long Video Dataset, Long Video Benchmark, Question Answering">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CinePile: A Long Video Question Answering Dataset and Benchmark</title>

  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-MFCT45H');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tifa.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="icon" href="static/images/cinepile_logo_v1.png" type="image/png"> <!-- For .png file -->
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MFCT45H" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yushi-hu.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://finegrainedrlhf.github.io/">
            Fine-Grained RLHF
          </a>
          <a class="navbar-item" href="https://yushi-hu.github.io/promptcap_demo/">
            PromptCap
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="display: flex; align-items: center;justify-content: center;">
              <img src="static/images/cinepile_logo_v1.png" alt="Logo" style="height: 175px;"> <!-- Adjust the path and the margin as needed -->
              CinePile: A Long Video Question Answering Dataset and Benchmark
            </h1>            
            <div class="is-size-5">
              <span class="author-block">
                <a href="https://ruchitrawal.github.io/" style="color:#008AD7;font-weight:normal;">Ruchit Rawal</a>,
                </span>
              <span class="author-block">
                <a href="https://khalidsaifullaah.github.io/" style="color:#008AD7;font-weight:normal;">Khalid Saifullah</a>,
                </span>
              <span class="author-block">
                  <a href="https://www.weizmann.ac.il/math/ronen/home" style="color:#f68946;font-weight:normal;">Ronen Basri</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.cs.umd.edu/~djacobs/" style="color:#008AD7;font-weight:normal;">David Jacobs</a>,
                    </span>
            </div>
            <div class="is-size-5">
              <span class="author-block">
                <a href="https://somepago.github.io/" style="color:#008AD7;font-weight:normal;">Gowthami Somepalli<sup>*</sup></a>,
                </span>
              <span class="author-block">
                <a href="https://www.cs.umd.edu/~tomg/" style="color:#008AD7;font-weight:normal;">Tom Goldstein<sup>*</sup></a>,
                </span>
            </div>
            
  
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">▶ </b>University of Maryland, College Park</span>
              <span class="author-block"><b style="color:#f68946; font-weight:normal">▶ </b>Weizmann Institute of Science</span>
              <span class="author-block">&nbsp;&nbsp;<sup>*</sup>Equal Contribution</span>
            </div>

            
              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2405.08813" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/tomg-group-umd/cinepile"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>CinePile Dataset</span>
                  </a>
                </span>

                <!-- code Link. -->
              <span class="link-block">
                <a href="https://colab.research.google.com/drive/1jDwvPoCsg9tck3dFhVCV-h3Ny6992wCr?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Colab Notebook</span>
                </a>
              </span>
    
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
      
        <div style="padding-bottom: 5px;">
          We present CinePile, a long-form video understanding dataset, created using advanced large language models (LLMs) with human-in-the-loop pipeline leveraging existing human-generated raw data.
      </div>
      
      <img src="./static/images/teaser_figure.png" alt="teaser" style="display: block; margin-top: 5px;">      

      


<h3 class="subtitle">
    <style>
      .subtitle a {
        color: blue;
      }
    </style>
<p>Our dataset comprises Multiple-Choice Questions across 86 diverse question templates, such as <em>Emotional Transition</em>, <em>Object's Description</em>, etc., generated automatically using Gemini. These templates are categorized into five high-level categories: Character and Relationship Dynamics (CRD), Narrative and Plot Analysis (NPA), Thematic Exploration (TE), Setting and Technical Analysis (STA), and Temporal (TE).</p>
</h3>


    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">A look at the dataset</h2>
        <div class="content has-text-justified">
          <p>
            <strong>Collecting video clips</strong><br>
            We divided 9,396 movie clips sourced from the <a href='https://www.youtube.com/@MOVIECLIPS'>Movieclips YouTube channel</a> into training and testing splits, containing 9,248 and 148 videos respectively. Following our question-answer generation and filtering pipeline, we produced <b>298,888 training points and 4,940 test-set points</b>, averaging about 32 questions per video scene.
          </p>
          <p>
            <strong>Dataset statistics</strong><br>
            For each question, we provide additional information, such as whether the questions are particularly challenging to answer (hardness) or if they require visual information (visual reliance) for an accurate response. 
          </p>
        </div>

  
      </div>
    </div>
    <!--/ Abstract -->
    <div class="image-row">
      <img src="./static/images/question_theme_dist.png" alt="Distribution of Question Themes">
      <img src="./static/images/hardness_stat.png" alt="Statistics on Question Hardness">
      <img src="./static/images/vision_reliance_stat.png" alt="Statistics on Vision Reliance">
  </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="privacy-auditing">Model evaluation</h2>
        <div class="content has-text-justified">
          <p>
            <strong>Model evaluation strategy</strong><br>
            Given that our dataset is of type multiple-choice question answers (MCQs), we evaluate a given model’s performance on our benchmark questions by measuring its ability to accurately select the right answer from a set of multiple-choice options, containing only one correct answer and four distractors. Our evaluation method incorporates a two-stage process to first reliably extract the selected choice from a model's response, and then compare whether the extracted response matches the correct answer key.
          </p>
          <p>
            <strong> Evaluation Results </strong> <br>
            Among the various commercial VLMs analyzed, GPT-4o, GPT-4 Vision and Gemini 1.5 Pro (Video) emerge as top performers, each achieving around 60% average performance. We note that all the models observe a drop of 15%-20% when evaluated on the hard split.
          </p>
          <img src="static/images/eval_table.png">
        </div>
      </div>
    </div>
  </div>
</section>





      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                    code</a> of this website,
                  we just ask that you link back to this page in the footer.
                  Please remember to remove the analytics code included in the header of the website which
                  you do not want on your website.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>
